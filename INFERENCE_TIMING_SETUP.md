# æ¨ç†æ—¶é—´è®°å½•è®¾ç½®å®Œæˆæ€»ç»“

## å·²å®Œæˆçš„ä¿®æ”¹

### 1. Benchmarker æ”¹è¿›ï¼ˆGGN & SparseSplatï¼‰

ä¸ºä¸¤ä¸ªé¡¹ç›®çš„ `src/misc/benchmarker.py` æ·»åŠ äº† CUDA åŒæ­¥æ”¯æŒï¼š

```python
@contextmanager
def time(self, tag: str, num_calls: int = 1, sync_cuda: bool = True):
    """
    Time a code block with optional CUDA synchronization.

    Args:
        tag: Name for this timing measurement
        num_calls: Number of logical calls (for averaging batch operations)
        sync_cuda: If True, synchronize CUDA before and after timing to ensure
                  accurate GPU operation timing
    """
    try:
        if sync_cuda and torch.cuda.is_available():
            torch.cuda.synchronize()
        start_time = time()
        yield
    finally:
        if sync_cuda and torch.cuda.is_available():
            torch.cuda.synchronize()
        end_time = time()
        for _ in range(num_calls):
            self.execution_times[tag].append((end_time - start_time) / num_calls)
```

**ä¸ºä»€ä¹ˆéœ€è¦ CUDA åŒæ­¥ï¼Ÿ**
- GPU æ“ä½œæ˜¯å¼‚æ­¥çš„ï¼ŒCPU å‘å‡º kernel è°ƒç”¨åç«‹å³è¿”å›
- æ²¡æœ‰åŒæ­¥çš„è¯åªèƒ½æµ‹é‡ CPU è°ƒåº¦æ—¶é—´ï¼Œä¸æ˜¯å®é™… GPU è®¡ç®—æ—¶é—´
- åŒæ­¥ç¡®ä¿åœ¨è®¡æ—¶å‰åæ‰€æœ‰ GPU æ“ä½œéƒ½å·²å®Œæˆ

### 2. GGN Model Wrapper ä¿®æ”¹

**æ–‡ä»¶**: `GGN/src/model/model_wrapper.py`

å¯ç”¨äº† encoder æ—¶é—´è®°å½•å¹¶æ·»åŠ  CUDA åŒæ­¥ï¼š

```python
# Line 201-206
# Time only the encoder inference (from input images to Gaussians prediction)
with self.benchmarker.time("encoder", sync_cuda=True):
    gaussians = self.encoder(
        batch["context"],
        self.global_step,
        deterministic=False,
    )

# Line 213
# Time decoder rendering (separate from encoder inference)
with self.benchmarker.time("decoder", num_calls=v, sync_cuda=True):
    ...
```

### 3. SparseSplat Model Wrapper ä¿®æ”¹

**æ–‡ä»¶**: `SparseSplat/src/model/model_wrapper.py`

æ·»åŠ äº†ä¸ GGN ä¸€è‡´çš„æ—¶é—´è®°å½•ï¼š

```python
# Line 400-406
# Time only the encoder inference (from input images to Gaussians prediction)
with self.benchmarker.time("encoder", sync_cuda=True):
    gaussians = self.encoder(
        batch["context"],
        self.global_step,
        deterministic=False,
        visualization_dump=visualization_dump,
    )

# Line 430
# Time decoder rendering (separate from encoder inference)
with self.benchmarker.time("decoder", num_calls=v, sync_cuda=True):
    ...
```

## æ—¶é—´è®°å½•çš„èŒƒå›´

### âœ… Encoder æ—¶é—´åŒ…å«

- å›¾åƒç‰¹å¾æå–
- æ·±åº¦é¢„æµ‹ï¼ˆå¦‚æœæœ‰ï¼‰
- é«˜æ–¯å‚æ•°ç”Ÿæˆ
- Encoder forward ä¸­çš„æ‰€æœ‰æ“ä½œ

### âŒ Encoder æ—¶é—´ä¸åŒ…å«

- æ•°æ®åŠ è½½ï¼ˆDataLoaderï¼‰
- æ•°æ®é¢„å¤„ç†å’Œè½¬æ¢ï¼ˆdata_shimï¼‰
- Decoder æ¸²æŸ“
- è¯„æµ‹æŒ‡æ ‡è®¡ç®—
- ç»“æœä¿å­˜ï¼ˆå›¾åƒã€è§†é¢‘ã€PLY ç­‰ï¼‰

### âœ… Decoder æ—¶é—´åŒ…å«

- é«˜æ–¯å…‰æ …åŒ–
- é¢œè‰²æ··åˆ
- æ¸²æŸ“å›¾åƒç”Ÿæˆ

### âŒ Decoder æ—¶é—´ä¸åŒ…å«

- åå¤„ç†
- ä¿å­˜å›¾åƒ
- è¯„æµ‹æŒ‡æ ‡è®¡ç®—

## å¦‚ä½•ä½¿ç”¨

### 1. è¿è¡Œ GGN è¯„æµ‹

```bash
cd /data/zhangzicheng/workspace/SparseSplat-/GGN

python -m src.main +experiment=dl3dv \
  mode=test \
  dataset.roots=[/path/to/dl3dv] \
  checkpointing.load=/path/to/ggn_checkpoint.ckpt \
  dataset/view_sampler=evaluation \
  dataset.view_sampler.index_path=assets/dl3dv_start_0_distance_50_ctx_6v_video_0_50.json \
  test.compute_scores=true \
  test.eval_time_skip_steps=5 \
  output_dir=outputs/ggn_dl3dv_6view
```

### 2. è¿è¡Œ SparseSplat è¯„æµ‹

```bash
cd /data/zhangzicheng/workspace/SparseSplat-/SparseSplat

python -m src.main +experiment=dl3dv \
  mode=test \
  dataset.roots=[/path/to/dl3dv] \
  checkpointing.load=/path/to/sparsesplat_checkpoint.ckpt \
  dataset/view_sampler=evaluation \
  dataset.view_sampler.index_path=assets/dl3dv_start_0_distance_50_ctx_6v_video_0_50.json \
  test.compute_scores=true \
  test.eval_time_skip_steps=5 \
  output_dir=outputs/sparsesplat_dl3dv_6view
```

### 3. å¯¹æ¯”ç»“æœ

```bash
cd /data/zhangzicheng/workspace/SparseSplat-

python compare_inference_time.py \
  --ggn GGN/outputs/ggn_dl3dv_6view/dl3dv/scores_all_avg.json \
  --sparsesplat SparseSplat/outputs/sparsesplat_dl3dv_6view/dl3dv/scores_all_avg.json
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
================================================================================
GGN vs SparseSplat - dl3dv æ•°æ®é›†è¯„æµ‹å¯¹æ¯”
================================================================================

ğŸ“Š æ¨ç†æ—¶é—´å¯¹æ¯” (Encoder: è¾“å…¥å›¾åƒ â†’ é«˜æ–¯ç‚¹äº‘)
--------------------------------------------------------------------------------
æŒ‡æ ‡                  GGN                       SparseSplat               å·®å¼‚
--------------------------------------------------------------------------------
Encoder å¹³å‡æ—¶é—´      234.5 ms                  189.2 ms                  +23.9%
Encoder è°ƒç”¨æ¬¡æ•°      100                       100
Decoder å¹³å‡æ—¶é—´      12.3 ms                   11.8 ms                   +4.2%
Decoder è°ƒç”¨æ¬¡æ•°      5000                      5000

ğŸ¨ æ¸²æŸ“è´¨é‡å¯¹æ¯”
--------------------------------------------------------------------------------
æŒ‡æ ‡                  GGN                       SparseSplat               å·®å¼‚
--------------------------------------------------------------------------------
PSNR â†‘               28.5234                   29.1245                   -0.6011 (SparseSplat âœ“)
SSIM â†‘               0.8912                    0.9023                    -0.0111 (SparseSplat âœ“)
LPIPS â†“              0.1234                    0.1156                    +0.0078 (SparseSplat âœ“)

================================================================================

ğŸ“Œ æ€»ç»“:
  â€¢ æ¨ç†é€Ÿåº¦: SparseSplat æ›´å¿« (19.3% å·®å¼‚)
  â€¢ æ¸²æŸ“è´¨é‡: SparseSplat æ›´å¥½ (åŸºäº PSNR)
```

## è¾“å‡ºæ–‡ä»¶è¯´æ˜

æ¯æ¬¡è¯„æµ‹ä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

```
outputs/
â””â”€â”€ {output_dir}/
    â””â”€â”€ dl3dv/
        â”œâ”€â”€ benchmark.json           # å®Œæ•´çš„æ—¶é—´è®°å½•ï¼ˆæ¯ä¸ªåœºæ™¯ï¼‰
        â”œâ”€â”€ peak_memory.json         # GPU å³°å€¼å†…å­˜
        â”œâ”€â”€ scores_all_avg.json      # å¹³å‡æŒ‡æ ‡å’Œæ—¶é—´ç»Ÿè®¡
        â”œâ”€â”€ scores_psnr_all.json     # æ¯ä¸ªåœºæ™¯çš„ PSNR
        â”œâ”€â”€ scores_ssim_all.json     # æ¯ä¸ªåœºæ™¯çš„ SSIM
        â””â”€â”€ scores_lpips_all.json    # æ¯ä¸ªåœºæ™¯çš„ LPIPS
```

### scores_all_avg.json æ ¼å¼

```json
{
  "encoder": [100, 0.2345],  // [è°ƒç”¨æ¬¡æ•°, å¹³å‡æ¯æ¬¡æ—¶é—´(ç§’)]
  "decoder": [5000, 0.0123],
  "psnr": 28.5234,
  "ssim": 0.8912,
  "lpips": 0.1234
}
```

## é…ç½®é€‰é¡¹

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `test.compute_scores` | `true` | æ˜¯å¦è®¡ç®—è¯„æµ‹æŒ‡æ ‡å’Œæ—¶é—´ç»Ÿè®¡ |
| `test.eval_time_skip_steps` | `0` | è·³è¿‡å‰ N æ­¥ç”¨äº GPU warmup |
| `output_dir` | - | è¾“å‡ºç›®å½•ï¼ˆå¿…éœ€ï¼‰ |

## Warmup æ­¥éª¤

- å‰å‡ ä¸ªæ¨ç†æ­¥éª¤é€šå¸¸è¾ƒæ…¢ï¼ˆGPU åˆå§‹åŒ–ã€CUDA kernel ç¼–è¯‘ç­‰ï¼‰
- é€šè¿‡ `test.eval_time_skip_steps` è·³è¿‡è¿™äº›æ­¥éª¤
- å»ºè®®è®¾ç½®ä¸º 5-10
- è·³è¿‡çš„æ­¥éª¤ä¸ä¼šè®¡å…¥å¹³å‡æ—¶é—´ç»Ÿè®¡

## æŠ€æœ¯ç»†èŠ‚

### CUDA åŒæ­¥çš„é‡è¦æ€§

```python
# é”™è¯¯æ–¹å¼ï¼ˆæ— åŒæ­¥ï¼‰- åªæµ‹é‡ CPU è°ƒåº¦æ—¶é—´
start = time()
output = model(input)  # CPU ç«‹å³è¿”å›ï¼ŒGPU è¿˜åœ¨åå°è®¡ç®—
end = time()  # âŒ é”™è¯¯çš„æ—¶é—´

# æ­£ç¡®æ–¹å¼ï¼ˆæœ‰åŒæ­¥ï¼‰- æµ‹é‡å®é™… GPU è®¡ç®—æ—¶é—´
torch.cuda.synchronize()  # ç­‰å¾…ä¹‹å‰çš„æ“ä½œå®Œæˆ
start = time()
output = model(input)
torch.cuda.synchronize()  # ç­‰å¾…å½“å‰æ“ä½œå®Œæˆ
end = time()  # âœ… æ­£ç¡®çš„æ—¶é—´
```

### æ‰¹å¤„ç†è¯´æ˜

- ä¸¤ä¸ªé¡¹ç›®åœ¨æµ‹è¯•æ—¶éƒ½ä½¿ç”¨ `batch_size=1`
- Decoder æ—¶é—´ä¼šé™¤ä»¥ target views æ•°é‡å¾—åˆ°å•å¸§æ—¶é—´
- è¿™ç¡®ä¿äº†å…¬å¹³å¯¹æ¯”

## è¿›ä¸€æ­¥å‚è€ƒ

- `GGN/INFERENCE_TIMING.md` - è¯¦ç»†çš„æŠ€æœ¯æ–‡æ¡£
- `SparseSplat/INFERENCE_TIMING.md` - åŒä¸Š
- `compare_inference_time.py` - å¯¹æ¯”è„šæœ¬æºç 

## æ•…éšœæ’é™¤

### é—®é¢˜ï¼šæ—¶é—´è®°å½•ä¸ºç©º

**åŸå› **ï¼š`test.compute_scores=false`

**è§£å†³**ï¼šè®¾ç½® `test.compute_scores=true`

### é—®é¢˜ï¼šEncoder æ—¶é—´ä¸º 0

**åŸå› **ï¼šä¹‹å‰è¢«æ³¨é‡Šæ‰äº†ï¼Œç°åœ¨å·²ä¿®å¤

**è§£å†³**ï¼šç¡®ä¿ä½¿ç”¨æœ€æ–°çš„ä»£ç 

### é—®é¢˜ï¼šæ—¶é—´ä¸ç¨³å®š

**åŸå› **ï¼šGPU è¿˜æœª warmup

**è§£å†³**ï¼šå¢åŠ  `test.eval_time_skip_steps` åˆ° 5-10
